{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in d:\\mada\\programs\\anaconda\\envs\\lab2\\lib\\site-packages (4.13.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\mada\\programs\\anaconda\\envs\\lab2\\lib\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in d:\\mada\\programs\\anaconda\\envs\\lab2\\lib\\site-packages (from beautifulsoup4) (4.12.2)\n"
     ]
    }
   ],
   "source": [
    "import sys , os\n",
    "!{sys.executable} -m pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HADOOP_HOME\"] = \"C:/Spark/spark-3.5.5-bin-hadoop3\"  \n",
    "os.environ[\"HADOOP_OPTS\"] = \"-Djava.library.path=C:/Spark/spark-3.5.5-bin-hadoop3/bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Users_Spark_Cleansing\")\\\n",
    "    .config(\"spark.executor.memory\", \"3g\")\\\n",
    "    .config(\"spark.jars.packages\", \"com.databricks:spark-xml_2.12:0.16.0,org.apache.parquet:parquet-hadoop:1.15.1\")\\\n",
    "    .config(\"spark.pyspark.python\", sys.executable) \\\n",
    "    .config(\"spark.pyspark.driver.python\", sys.executable) \\\n",
    "    .config(\"spark.hadoop.io.native.lib.available\", \"false\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+------------------+----------+---+--------------------+--------------------+-----------+--------+------+--------------------+\n",
      "|            _AboutMe|_AccountId|       _CreationDate|      _DisplayName|_DownVotes|_Id|     _LastAccessDate|           _Location|_Reputation|_UpVotes|_Views|         _WebsiteUrl|\n",
      "+--------------------+----------+--------------------+------------------+----------+---+--------------------+--------------------+-----------+--------+------+--------------------+\n",
      "|<p>Hi, I'm not re...|        -1|2010-07-19 09:55:...|         Community|      9720| -1|2010-07-19 09:55:...|  on the server farm|          1|   17823|  3131|http://meta.stack...|\n",
      "|<p>Dev #2 who hel...|         2|2010-07-19 17:01:...|      Geoff Dalgas|         0|  2|2019-02-08 00:01:...|       Corvallis, OR|        101|       3|    49|http://stackoverf...|\n",
      "|<p>Former <a href...|         3|2010-07-19 18:34:...|      Jarrod Dixon|         0|  3|2019-02-07 18:22:...|Johnson City, TN,...|        101|      23|    50|http://jarroddixo...|\n",
      "|<p>co-founder of ...|      1998|2010-07-19 22:03:...|            Emmett|         0|  4|2016-11-24 21:37:...|   San Francisco, CA|        101|       0|    24|http://minesweepe...|\n",
      "|<p>Quantitative r...|     54503|2010-07-19 22:03:...|             Shane|         5|  5|2022-12-07 21:30:...|        New York, NY|      12151|     684|  2101|http://www.statal...|\n",
      "|<ul>\\n<li>PhD in ...|     46050|2010-07-19 22:04:...|            Harlan|         0|  6|2022-07-14 19:07:...|   Brooklyn, NY, USA|        842|      65|   217|http://www.harlan...|\n",
      "|I'm a recent grad...|     49514|2010-07-19 22:04:...|             Vince|         0|  7|2023-07-02 08:09:...|           Davis, CA|        805|      71|   115|http://bioinforma...|\n",
      "|<p>I'm a senior s...|     70002|2010-07-19 22:04:...|       csgillespie|        29|  8|2023-09-01 15:47:...|Newcastle, United...|      12069|     635|  2167|https://www.jumpi...|\n",
      "|Bioinformatician\\...|     23234|2010-07-19 22:05:...|            Pierre|         0| 10|2023-03-22 13:15:...|              France|        131|       8|    27|http://plindenbau...|\n",
      "|<p>data_stuff &lt...|     47893|2010-07-19 22:06:...|          wahalulu|         0| 11|2023-08-08 05:11:...|      Washington, DC|        171|      10|    19|http://www.linked...|\n",
      "|<p>I used to desi...|     21721|2010-07-19 22:06:...|               Jin|         0| 12|2020-04-15 00:27:...|         Raleigh, NC|        101|       5|    23| http://www.8164.org|\n",
      "|Undergraduate stu...|     46029|2010-07-19 22:06:...|           Sharpie|         1| 13|2014-08-14 20:28:...|       United States|       4296|      44|   467|http://www.sharps...|\n",
      "|                    |    189902|2010-07-19 22:07:...|     hannes.koller|         0| 15|2021-04-12 07:46:...|     Vienna, Austria|        111|       0|     9|http://soma.denkt...|\n",
      "|                NULL|     10996|2010-07-19 22:08:...|         slashnick|         0| 16|2019-07-31 13:31:...|London, United Ki...|        101|       7|     7|                NULL|\n",
      "|                    |    509454|2010-07-19 22:08:...|            Random|         1| 17|2010-09-10 10:34:...|                NULL|       2250|      13|    72|                NULL|\n",
      "|<p>Software engin...|     69872|2010-07-19 22:08:...|            grokus|         0| 18|2021-03-10 00:56:...|       United States|        233|      16|    20|http://wikipedia.org|\n",
      "|<p>Associate Prof...|    501919|2010-07-19 22:08:...|       Noah Snyder|         0| 19|2023-05-15 03:42:...|Bloomington, Indiana|        101|       5|    15|http://sbseminar....|\n",
      "|                NULL|     40640|2010-07-19 22:08:...|Waleed Al-Balooshi|         0| 21|2011-09-26 04:28:...|            Michigan|        101|       0|    11|                NULL|\n",
      "|<p>Working with d...|    124416|2010-07-19 22:09:...|             radek|         8| 22|2023-02-14 22:37:...|Brisbane QLD, Aus...|       1377|    1151|   300|http://www.ispm.u...|\n",
      "|<p>The first comp...|     21565|2010-07-19 22:09:...|       Jay Stevens|         1| 23|2023-04-09 02:38:...|Jacksonville, FL,...|        619|      86|   114|                NULL|\n",
      "+--------------------+----------+--------------------+------------------+----------+---+--------------------+--------------------+-----------+--------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Users_df = spark.read.format(\"xml\") \\\n",
    "    .option(\"rowTag\", \"row\") \\\n",
    "    .load(\"Dataset/Users.xml\")\n",
    "\n",
    "Users_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate nulls in each column\n",
    "from pyspark.sql.functions import col, count, when\n",
    "\n",
    "null_perc=Users_df.select([((count(when(col(c).isNull(),c)) / Users_df.count()) * 100).alias(c) for c in Users_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-------------+------------+----------+---+---------------+----------------+-----------+--------+------+-----------------+\n",
      "|         _AboutMe|         _AccountId|_CreationDate|_DisplayName|_DownVotes|_Id|_LastAccessDate|       _Location|_Reputation|_UpVotes|_Views|      _WebsiteUrl|\n",
      "+-----------------+-------------------+-------------+------------+----------+---+---------------+----------------+-----------+--------+------+-----------------+\n",
      "|79.84055556887088|0.00479351916209285|          0.0|         0.0|       0.0|0.0|            0.0|74.0907293339405|        0.0|     0.0|   0.0|87.49640486062843|\n",
      "+-----------------+-------------------+-------------+------------+----------+---+---------------+----------------+-----------+--------+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "null_perc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+----------+---+--------------------+-----------+--------+------+\n",
      "|       _CreationDate|      _DisplayName|_DownVotes|_Id|     _LastAccessDate|_Reputation|_UpVotes|_Views|\n",
      "+--------------------+------------------+----------+---+--------------------+-----------+--------+------+\n",
      "|2010-07-19 09:55:...|         Community|      9720| -1|2010-07-19 09:55:...|          1|   17823|  3131|\n",
      "|2010-07-19 17:01:...|      Geoff Dalgas|         0|  2|2019-02-08 00:01:...|        101|       3|    49|\n",
      "|2010-07-19 18:34:...|      Jarrod Dixon|         0|  3|2019-02-07 18:22:...|        101|      23|    50|\n",
      "|2010-07-19 22:03:...|            Emmett|         0|  4|2016-11-24 21:37:...|        101|       0|    24|\n",
      "|2010-07-19 22:03:...|             Shane|         5|  5|2022-12-07 21:30:...|      12151|     684|  2101|\n",
      "|2010-07-19 22:04:...|            Harlan|         0|  6|2022-07-14 19:07:...|        842|      65|   217|\n",
      "|2010-07-19 22:04:...|             Vince|         0|  7|2023-07-02 08:09:...|        805|      71|   115|\n",
      "|2010-07-19 22:04:...|       csgillespie|        29|  8|2023-09-01 15:47:...|      12069|     635|  2167|\n",
      "|2010-07-19 22:05:...|            Pierre|         0| 10|2023-03-22 13:15:...|        131|       8|    27|\n",
      "|2010-07-19 22:06:...|          wahalulu|         0| 11|2023-08-08 05:11:...|        171|      10|    19|\n",
      "|2010-07-19 22:06:...|               Jin|         0| 12|2020-04-15 00:27:...|        101|       5|    23|\n",
      "|2010-07-19 22:06:...|           Sharpie|         1| 13|2014-08-14 20:28:...|       4296|      44|   467|\n",
      "|2010-07-19 22:07:...|     hannes.koller|         0| 15|2021-04-12 07:46:...|        111|       0|     9|\n",
      "|2010-07-19 22:08:...|         slashnick|         0| 16|2019-07-31 13:31:...|        101|       7|     7|\n",
      "|2010-07-19 22:08:...|            Random|         1| 17|2010-09-10 10:34:...|       2250|      13|    72|\n",
      "|2010-07-19 22:08:...|            grokus|         0| 18|2021-03-10 00:56:...|        233|      16|    20|\n",
      "|2010-07-19 22:08:...|       Noah Snyder|         0| 19|2023-05-15 03:42:...|        101|       5|    15|\n",
      "|2010-07-19 22:08:...|Waleed Al-Balooshi|         0| 21|2011-09-26 04:28:...|        101|       0|    11|\n",
      "|2010-07-19 22:09:...|             radek|         8| 22|2023-02-14 22:37:...|       1377|    1151|   300|\n",
      "|2010-07-19 22:09:...|       Jay Stevens|         1| 23|2023-04-09 02:38:...|        619|      86|   114|\n",
      "+--------------------+------------------+----------+---+--------------------+-----------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Users_df=Users_df.drop(*[\"_Location\",\"_AccountId\",\"_AboutMe\",\"_WebsiteURL\"])\n",
    "Users_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming Columns Names\n",
    "for col_name in Users_df.columns:\n",
    "    Users_df = Users_df.withColumnRenamed(col_name, col_name.lstrip(\"_\"))\n",
    "\n",
    "Users_df=Users_df.withColumnRenamed(\"Id\",\"UsersId_BK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+---------+----------+--------------+----------+-------+-----+-----+\n",
      "|CreationDate|DisplayName|DownVotes|UsersId_BK|LastAccessDate|Reputation|UpVotes|Views|count|\n",
      "+------------+-----------+---------+----------+--------------+----------+-------+-----+-----+\n",
      "+------------+-----------+---------+----------+--------------+----------+-------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check if thier is duplicates\n",
    "duplicate_count = Users_df.groupBy(Users_df.columns).count().filter(col(\"count\") > 1)\n",
    "duplicate_count.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CreationDate: timestamp (nullable = true)\n",
      " |-- DisplayName: string (nullable = true)\n",
      " |-- DownVotes: long (nullable = true)\n",
      " |-- UsersId_BK: long (nullable = true)\n",
      " |-- LastAccessDate: timestamp (nullable = true)\n",
      " |-- Reputation: long (nullable = true)\n",
      " |-- UpVotes: long (nullable = true)\n",
      " |-- Views: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Users_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CreationDate: date (nullable = true)\n",
      " |-- DisplayName: string (nullable = true)\n",
      " |-- DownVotes: integer (nullable = true)\n",
      " |-- UsersId_BK: integer (nullable = true)\n",
      " |-- LastAccessDate: date (nullable = true)\n",
      " |-- Reputation: integer (nullable = true)\n",
      " |-- UpVotes: integer (nullable = true)\n",
      " |-- Views: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert DataTypes\n",
    "from pyspark.sql.functions import to_date, col\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# convert to date\n",
    "Users_df = Users_df.withColumn(\"CreationDate\", to_date(col(\"CreationDate\"), \"yyyy-MM-dd\")).withColumn(\"LastAccessDate\", to_date(col(\"LastAccessDate\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "#convert to Integer\n",
    "columns_to_convert = [\"DownVotes\", \"UpVotes\", \"Views\",\"Reputation\",\"UsersId_BK\"]\n",
    "for col_name in columns_to_convert:\n",
    "    Users_df = Users_df.withColumn(col_name, col(col_name).cast(IntegerType()))\n",
    "\n",
    "Users_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Users_df.write.mode(\"overwrite\").parquet(\"SilverDataSet/Users\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lab2)",
   "language": "python",
   "name": "lab2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
